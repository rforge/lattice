\documentclass[10pt]{article}


\title{Getting Started with Lattice Graphics}
\author{Deepayan Sarkar}
\date{}


\usepackage[text={6.5in,8.5in},centering]{geometry}
\usepackage{Sweave}
\usepackage[round]{natbib}
\usepackage{alltt}
\usepackage{graphicx}
\usepackage{url}
\usepackage{hyperref}
\setkeys{Gin}{width=0.98\textwidth}

\newcommand{\fixme}[1]{\emph{\small \textbf{#1}}}
\newcommand{\R}{\textsf{R}}
\newcommand{\code}[1]{\texttt{#1}}
\newcommand{\lattice}{\code{lattice}}
\newcommand{\Rpackage}[1]{\code{#1}}
\newcommand{\Rfunction}[1]{\code{#1()}}
\newcommand{\class}[1]{\textit{``#1''}}


\newcommand{\dontshow}[1]{}

\newtheorem{exercise}{Exercise}
\newenvironment{solution}{}{}


\begin{document}
\maketitle

\raggedright









\lattice\ is an add-on package that implements Trellis graphics
(originally developed for \textsf{S} and \textsf{S-PLUS}) in \R.  It
is a powerful and elegant high-level data visualization system, with
an emphasis on multivariate data, that is sufficient for typical
graphics needs, and is also flexible enough to handle most nonstandard
requirements.  This lab covers the basics of \lattice\ and gives
pointers to further resources.


\section*{Some examples}


To fix ideas, we start with a few simple examples. We use the
\code{Chem97} dataset from the \Rpackage{mlmRev} package.
\begin{Schunk}
\begin{Sinput}
> data(Chem97, package = "mlmRev")
> head(Chem97)
\end{Sinput}
\begin{Soutput}
  lea school student score gender age gcsescore   gcsecnt
1   1      1       1     4      F   3     6.625 0.3393157
2   1      1       2    10      F  -3     7.625 1.3393157
3   1      1       3    10      F  -4     7.250 0.9643157
4   1      1       4    10      F  -2     7.500 1.2143157
5   1      1       5     8      F  -1     6.444 0.1583157
6   1      1       6    10      F   4     7.750 1.4643157
\end{Soutput}
\end{Schunk}
%
The dataset records information on students appearing in the 1997
A-level chemistry examination in Britain.  We are only interested in
the following variables:
\begin{itemize}
\item \code{score}: point score in the A-level exam, with six possible
  values (0, 2, 4, 6, 8).
\item \code{gcsescore}: average score in GCSE exams.  This is a
  continuous score that may be used as a predictor of the A-level
  score.
\item \code{gender}: gender of the student.
\end{itemize}

\newpage

Using \lattice, we can draw a histogram of all the \code{gcsescore}
values using
\begin{Schunk}
\begin{Sinput}
> histogram(~ gcsescore, data = Chem97)
\end{Sinput}
\end{Schunk}
%
\begin{center}
\includegraphics{figs/intro-004}
\end{center}
This plot shows a reasonably symmetric unimodal distribution, but is
otherwise uninteresting.  A more interesting display would be one
where the distribution of \code{gcsescore} is \emph{compared} across
different subgroups, say those defined by the A-level exam score.
This can be done using
\begin{Schunk}
\begin{Sinput}
> histogram(~ gcsescore | factor(score), data = Chem97)
\end{Sinput}
\end{Schunk}
%
\begin{center}
\includegraphics{figs/intro-006}
\end{center}


\newpage

More effective comparison is enabled by direct superposition.  This is
hard to do with conventional histograms, but easier using kernel
density estimates.  In the following example, we use the same
subgroups as before in the different panels, but additionally
subdivide the \code{gcsescore} values by \code{gender} within each
panel.
\begin{Schunk}
\begin{Sinput}
> densityplot(~ gcsescore | factor(score), Chem97, groups = gender,
              plot.points = FALSE, auto.key = TRUE)
\end{Sinput}
\end{Schunk}
%
\begin{center}
\includegraphics{figs/intro-008}
\end{center}

\begin{exercise}
  What happens if the extra arguments \code{plot.points} and
  \code{auto.key} are omitted?  What happens if the inline call to
  \Rfunction{factor} is omitted?
\end{exercise}

\begin{solution}
  The \code{plot.points} argument is described in the
  \code{?panel.densityplot} help page, and \code{auto.key} in
  \code{?xyplot}.  Without the call to \Rfunction{factor},
  \code{score} is considered to be a numeric variable, and converted
  into a ``shingle''; see \code{?shingle}.
\end{solution}

\begin{exercise}
  \lattice\ uses a system of customizable settings to derive default
  graphical parameters.  Notice that the estimated densities for the
  two genders are distinguished by differing line types.  Is this also
  true if you run the same commands in an interactive session?  Which
  do you think is more effective?
\end{exercise}

\begin{solution}
  See \code{?trellis.device}.
\end{solution}



\newpage

\section*{Basic ideas}


\lattice\ provides a high-level system for statistical graphics that
is independent of traditional \R\ graphics.
\begin{itemize}
\item It is modeled on the Trellis suite in \textsf{S-PLUS}, and
  implements most of its features.  In fact, \lattice\ can be
  considered an implementation of the general principles of Trellis
  graphics \citep{becker1996vda}.
\item It uses the \Rpackage{grid} package \citep{murrell2005} as the
  underlying implementation engine, and thus inherits many of its
  features by default.
\end{itemize}
Trellis displays are defined by the \textbf{type} of graphic and the
\textbf{role} different variables play in it.  Each display type is
associated with a corresponding \emph{high-level} function
(\code{histogram}, \code{densityplot}, etc.).  Possible roles depend
on the type of display, but typical ones are
\begin{itemize}
\item primary variables: those that define the primary display (e.g.,
  \code{gcsescore} in the previous examples).
\item conditioning variables: divides data into subgroups, each of
  which are presented in a different panel (e.g., \code{score} in the
  last two examples).
\item grouping variables: subgroups are contrasted within panels by
  superposing the corresponding displays (e.g., \code{gender} in the
  last example).
\end{itemize}
The following display types are available in \lattice.
\begin{center}
  \begin{tabular}{ll}
    \hline
    \textbf{Function} & \textbf{Default Display} \\
    \hline
    \Rfunction{histogram} & Histogram \\
    \Rfunction{densityplot}~~~~~ & Kernel Density Plot \\
    \Rfunction{qqmath} & Theoretical Quantile Plot  \\
    \Rfunction{qq} & Two-sample Quantile Plot \\
    \Rfunction{stripplot} & Stripchart (Comparative 1-D Scatter Plots) \\
    \Rfunction{bwplot} & Comparative Box-and-Whisker Plots \\
    \Rfunction{dotplot} & Cleveland Dot Plot \\
    \Rfunction{barchart} & Bar Plot \\
    \Rfunction{xyplot} & Scatter Plot \\
    \Rfunction{splom} & Scatter-Plot Matrix \\
    \Rfunction{contourplot} & Contour Plot of Surfaces \\
    \Rfunction{levelplot} & False Color Level Plot of Surfaces \\
    \Rfunction{wireframe} & Three-dimensional Perspective Plot of Surfaces  \\
    \Rfunction{cloud} & Three-dimensional Scatter Plot \\
    \Rfunction{parallel} & Parallel Coordinates Plot \\
    \hline
  \end{tabular}
\end{center}
New high-level functions can be written to represent further
visualization types; examples are \Rfunction{ecdfplot} and
\Rfunction{mapplot} in the \Rpackage{latticeExtra} package.


\newpage

\section*{Design goals}


Visualization is an art, but it can benefit greatly from a systematic,
scientific approach.  In particular, \citet{Clev:EOGD} has shown that
it is possible to come up with general rules that can be applied to
design more effective graphs.



~~~~One of the primary goals of Trellis graphics is to provide tools
that make it easy to apply these rules, so that the burden of
compliance is shifted from the user to the software to the extent
possible.  Some obvious examples of such rules are:
\begin{itemize}
\item Use as much of the available space as possible
\item Force direct comparsion by superposition (grouping) when
  possible
\item Encourage comparison when juxtaposing (conditioning): use common
  axes, add common reference objects such as grids.
\end{itemize}
These design goals have some technical drawbacks; for example,
non-wastage of space requires the complete display to be known when
plotting begins, so, the incremental approach common in traditional
\R\ graphics (e.g., adding a main title after the main plot is
finished) doesn't fit in.  \lattice\ deals with this using an
object-based paradigm: plots are represented as regular \R\ objects,
incremental updates are performed by modifying such objects and
re-plotting them.



~~~~While rules are useful, any serious graphics system must also be
flexible.  \lattice\ is designed to be flexible, but obviously there
is a trade-off between flexibility and ease of use for the more common
tasks.  \lattice\ tries to achieve a balance using the following
model:
\begin{itemize}
\item A display is made up of various elements
\item The defaults are coordinated to provide meaningful results, but
\item Each element can be controlled by the user independently of the
  others
\item The main elements are:
  \begin{itemize}
  \item the primary (panel) display
  \item axis annotation
  \item strip annotation (describing the conditioning process)
  \item legends (typically describing the grouping process)
  \end{itemize}
\end{itemize}
In each case, additional arguments to the high-level calls can be used
to activate common variants, and full flexibility is allowed through
arbitrary user-defined functions.  This is particularly useful for
controlling the primary display through panel functions.


~~~~Most nontrivial use of \lattice\ involves manipulation of one or
more of these elements.
% Much confusion can be avoided once the separation of these elements
% is appreciated.
Not all graphical designs segregate neatly into these elements;
\lattice\ may not be a good tool for such displays.

\newpage


\section*{Common high-level functions}

\subsection*{Visualizing univariate distributions}


Several standard statistical graphics are intended to visualize the
distribution of a continuous random variable.  We have already seen
histograms and density plots, which are both estimates of the
probability density function.  Another useful display is the normal
Q-Q plot, which is related to the distribution function $F(x) = P(X
\leq x)$.  Normal Q-Q plots can be produced by the \lattice\ function
\Rfunction{qqmath}.
\begin{Schunk}
\begin{Sinput}
> qqmath(~ gcsescore | factor(score), Chem97, groups = gender,
         f.value = ppoints(100), auto.key = TRUE, 
         type = c("p", "g"), aspect = "xy")
\end{Sinput}
\end{Schunk}
\begin{center}
\includegraphics{figs/intro-010}
\end{center}
Normal Q-Q plots plot empirical quantiles of the data against
quantiles of the normal distribution (or some other theoretical
distribution).  They can be regarded as an estimate of the
distribution function $F$, with the probability axis transformed by
the normal quantile function.  They are designed to detect departures
from normality; for a good fit, the points lie approximate along a
straight line.  In the plot above, the systematic convexity suggests
that the distributions are left-skewed, and the change in slopes
suggests changing variance.

~~~~The \code{type} argument adds a common reference grid to each
panel that makes it easier to see the upward shift in \code{gcsescore}
across panels.  The \code{aspect} argument automatically computes an
aspect ratio.


\newpage


Two-sample Q-Q plots compare quantiles of two samples (rather than one
sample and a theoretical distribution).  They can be produced by the
\lattice\ function \Rfunction{qq}, with a formula that has two primary
variables.  In the formula \code{y \~\ x}, \code{y} needs to be a
factor with two levels, and the samples compared are the subsets of
\code{x} for the two levels of \code{y}.  For example, we can compare
the distributions of \code{gcsescore} for males and females,
conditioning on A-level score, with
\begin{Schunk}
\begin{Sinput}
> qq(gender ~ gcsescore | factor(score), Chem97, 
     f.value = ppoints(100), type = c("p", "g"), aspect = 1)
\end{Sinput}
\end{Schunk}
\begin{center}
\includegraphics{figs/intro-012}
\end{center}
The plot suggests that females do better than males in the GCSE exam
for a given A-level score (in other words, males tend to improve more
from the GCSE exam to the A-level exam), and also have smaller
variance (except in the first panel).




\newpage

Two-sample Q-Q plots only allow comparison between two samples at a
time.  A well-known graphical design that allows comparison between an
arbitrary number of samples is the comparative box-and-whisker plot.
They are related to the Q-Q plot: the values compared are five
``special'' quantiles, the median, the first and third quartiles, and
the extremes.  More commonly, the extents of the ``whiskers'' are
defined differently, and values outside plotted explicitly, so that
heavier-than-normal tails tend to produce many points outside the
extremes.  See \code{?boxplot.stats} for details.


~~~~Box-and-whisker plots can be produced by the \lattice\ function
\Rfunction{bwplot}.  
\begin{Schunk}
\begin{Sinput}
> bwplot(factor(score) ~ gcsescore | gender, Chem97)
\end{Sinput}
\end{Schunk}
\begin{center}
\includegraphics{figs/intro-014}
\end{center}
The decreasing lengths of the boxes and whiskers suggest decreasing
variance, and the large number of outliers on one side indicate
heavier left tails (characteristic of a left-skewed distribution).




\newpage


The same box-and-whisker plots can be displayed in a slightly
different layout to emphasize a more subtle effect in the data: for
example, the median \code{gcsescore} does not uniformly increase from
left to right in the following plot, as one might have expected.
\begin{Schunk}
\begin{Sinput}
> bwplot(gcsescore ~ gender | factor(score), Chem97, layout = c(6, 1))
\end{Sinput}
\end{Schunk}
\begin{center}
\includegraphics{figs/intro-016}
\end{center}
The \code{layout} argument controls the layout of panels in columns,
rows, and pages (the default would not have been as useful in this
example).  Note that the box-and-whisker plots are now vertical,
because of a switch in the order of variables in the formula.

\begin{exercise}
  All the plots we have seen suggest that the distribution of
  \code{gcsescore} is slightly skewed, and have unequal variances in
  the subgroups of interest.  Using a Box--Cox transformation often
  helps in such situations.  The \Rfunction{boxcox} function in the
  \code{MASS} package can be used to find the ``optimal'' Box--Cox
  transformation, which in this case is approximate $2.34$.  Reproduce
  the previous plots replacing \code{gcsescore} by
  \code{gcsescore\^{}2.34}.  Would you say the transformation was
  successful?
\end{exercise}

\begin{exercise}
  Not all tools are useful for all problems.  Box-and-whisker plots,
  and to a lesser extent Q-Q plots, are mostly useful when the
  distributions are symmetric and unimodal, and can be misleading
  otherwise.  For example, consider the display produced by
\begin{Schunk}
\begin{Sinput}
> data(gvhd10, package = "latticeExtra")
> bwplot(Days ~ log(FSC.H), data = gvhd10)
\end{Sinput}
\end{Schunk}
  %
  What would you conclude about the distribution of \code{log(FSC.H)} 
  from this plot? Now draw kernel density plots of \code{log(FSC.H)}
  conditioning on \code{Days}.  Would you reach the same conclusions
  as before?
\end{exercise}


\newpage


For small samples, summarizing is often unnecessary, and simply
plotting all the data reveals interesting features of the
distribution.  The following example, which uses the \code{quakes}
dataset, plots depths of earthquake epicenters by magnitude.
\begin{Schunk}
\begin{Sinput}
> stripplot(depth ~ factor(mag), data = quakes,
            jitter.data = TRUE, alpha = 0.6, 
            main = "Depth of earthquake epicenters by magnitude",
            xlab = "Magnitude (Richter)",
            ylab = "Depth (km)")
\end{Sinput}
\end{Schunk}
\begin{center}
\includegraphics{figs/intro-019}
\end{center}
This is known as a strip plot of a 1-D scatter plot.  Note the use of
jittering and partial transparency to alleviate potential
overplotting.  The arguments \code{xlab}, \code{ylab}, and \code{main}
have been used to add informative labels; this is possible in all
high-level \lattice\ functions.



\newpage

\subsection*{Visualizing tabular data}


Tables form an important class of statistical data.  Popular
visualization methods designed for tables are bar charts and Cleveland
dot plots.\footnote{Pie charts are also popular, but they have serious
  design flaws and should not be used.  \lattice\ does not have a
  high-level function that produces pie charts.  }  For illustration,
we use the \code{VADeaths} dataset, which gives death rates in the
U.S. state of Virginia in 1941 among different population subgroups.
\code{VADeaths} is a matrix.
\begin{Schunk}
\begin{Sinput}
> VADeaths
\end{Sinput}
\begin{Soutput}
      Rural Male Rural Female Urban Male Urban Female
50-54       11.7          8.7       15.4          8.4
55-59       18.1         11.7       24.3         13.6
60-64       26.9         20.3       37.0         19.3
65-69       41.0         30.9       54.6         35.1
70-74       66.0         54.3       71.1         50.0
\end{Soutput}
\end{Schunk}
%
To use the \lattice\ formula interface, we first need to convert it
into a data frame.
\begin{Schunk}
\begin{Sinput}
> VADeathsDF <- as.data.frame.table(VADeaths, responseName = "Rate")
> VADeathsDF
\end{Sinput}
\begin{Soutput}
    Var1         Var2 Rate
1  50-54   Rural Male 11.7
2  55-59   Rural Male 18.1
3  60-64   Rural Male 26.9
4  65-69   Rural Male 41.0
5  70-74   Rural Male 66.0
6  50-54 Rural Female  8.7
7  55-59 Rural Female 11.7
8  60-64 Rural Female 20.3
9  65-69 Rural Female 30.9
10 70-74 Rural Female 54.3
11 50-54   Urban Male 15.4
12 55-59   Urban Male 24.3
13 60-64   Urban Male 37.0
14 65-69   Urban Male 54.6
15 70-74   Urban Male 71.1
16 50-54 Urban Female  8.4
17 55-59 Urban Female 13.6
18 60-64 Urban Female 19.3
19 65-69 Urban Female 35.1
20 70-74 Urban Female 50.0
\end{Soutput}
\end{Schunk}
%
Bar charts are produced by the \Rfunction{barchart} function, and
Cleveland dot plots by \Rfunction{dotplot}.  Both allow a formula of
the form \code{y \~\ x} (plus additional conditioning and grouping
variables), where one of \code{x} and \code{y} should be a factor.

\newpage


A bar chart of the \code{VADeathsDF} data is produced by
\begin{Schunk}
\begin{Sinput}
> barchart(Var1 ~ Rate | Var2, VADeathsDF, layout = c(4, 1))
\end{Sinput}
\end{Schunk}
\begin{center}
\includegraphics{figs/intro-023}
\end{center}
This plot is potentially misleading, because a strong visual effect in
the plot is the comparison of the areas of the shaded bars, which do
not mean anything.  This problem can be addressed by making the areas
proportional to the values they encode.
\begin{Schunk}
\begin{Sinput}
> barchart(Var1 ~ Rate | Var2, VADeathsDF, layout = c(4, 1), origin = 0)
\end{Sinput}
\end{Schunk}
\begin{center}
\includegraphics{figs/intro-025}
\end{center}

\newpage

A better design is to altogether forego the bars, which distract from
the primary comparison of the endpoint positions, and instead use a
dot plot.
\begin{Schunk}
\begin{Sinput}
> dotplot(Var1 ~ Rate | Var2, VADeathsDF, layout = c(4, 1))
\end{Sinput}
\end{Schunk}
\begin{center}
\includegraphics{figs/intro-027}
\end{center}
In this particular example, the display is more effective if we use
\code{Var2} as a grouping variable, and join the points within each
group.  
\begin{Schunk}
\begin{Sinput}
> dotplot(Var1 ~ Rate, data = VADeathsDF, groups = Var2, type = "o", 
          auto.key = list(space = "right", points = TRUE, lines = TRUE))
\end{Sinput}
\end{Schunk}
\begin{center}
\includegraphics{figs/intro-029}
\end{center}
This plot clearly shows that the pattern of death rate by age is
virtually identical for urban and rural females, with an increased
rate for rural males, and a further increase for urban males.  This
interaction is difficult to see in the earlier plots.



\newpage

\subsection*{Generic functions and methods}

High-level \lattice\ functions are actually generic functions, with
specific methods doing the actual work.  All the examples we have seen
so far use the \class{formula} methods; that is, the method called
when the first argument is a formula.  Because \Rfunction{barchart}
and \Rfunction{dotplot} are frequently used for multiway tables stored
as arrays, \lattice\ also includes suitable methods that bypass the
conversion to a data frame that would be required otherwise.  For
example, an alternative to the last example is
\begin{Schunk}
\begin{Sinput}
> dotplot(VADeaths, type = "o",
          auto.key = list(points = TRUE, lines = TRUE, space = "right"))
\end{Sinput}
\end{Schunk}
\begin{center}
\includegraphics{figs/intro-031}
\end{center}
Methods available for a particular generic can be listed
using\footnote{This is only true for \textsf{S3} generics and methods.
  \lattice\ can be extended to use the \textsf{S4} system as well,
  although we will not discuss such extensions here.  }
\begin{Schunk}
\begin{Sinput}
> methods(generic.function = "dotplot")
\end{Sinput}
\begin{Soutput}
[1] dotplot.array*   dotplot.default* dotplot.formula*
[4] dotplot.matrix*  dotplot.numeric* dotplot.table*  

   Non-visible functions are asterisked
\end{Soutput}
\end{Schunk}
%
The special features of the methods, if any, are described in their
respective help pages; for example, \code{?dotplot.matrix} for the
example above.
\begin{exercise}
  Reproduce the ungrouped dot plot using the \class{matrix} method.
\end{exercise}

\newpage

\subsection*{Scatter plots and extensions}


Scatter plots are commonly used for continuous bivariate data, as well
as for time-series data.  We use the \code{Earthquake} data, which
contains measurements recorded at various seismometer locations for 23
large earthquakes in western North America between 1940 and 1980.  Our
first example plots the maximum horizontal acceleration measured
against distance of the measuring station from the epicenter.
\begin{Schunk}
\begin{Sinput}
> data(Earthquake, package = "nlme")
> xyplot(accel ~ distance, data = Earthquake)
\end{Sinput}
\end{Schunk}
\begin{center}
\includegraphics{figs/intro-034}
\end{center}
The plot shows patterns typical of a right skewed distribution, and
can be improved by plotting the data on a log scale.  It is common to
add a reference grid and some sort of smooth; for example,
\begin{Schunk}
\begin{Sinput}
> xyplot(accel ~ distance, data = Earthquake, scales = list(log = TRUE), 
         type = c("p", "g", "smooth"), xlab = "Distance From Epicenter (km)",
         ylab = "Maximum Horizontal Acceleration (g)")
\end{Sinput}
\end{Schunk}
\begin{center}
\includegraphics{figs/intro-036}
\end{center}


\newpage

\subsection*{Shingles}

Conditioning by factors is possible with scatter plots as usual.  It
is also possible to condition on shingles, which are continuous
analogues of factors, with levels defined by possibly overlapping
intervals.  Using the \code{quakes} dataset again, we can try to
understand the three-dimensional distribution of earthquake epicenters
by looking at a series of two-dimensional scatter plots.
\begin{Schunk}
\begin{Sinput}
> Depth <- equal.count(quakes$depth, number=8, overlap=.1)
> summary(Depth)
\end{Sinput}
\begin{Soutput}
Intervals:
    min   max count
1  39.5  63.5   138
2  60.5 102.5   138
3  97.5 175.5   138
4 161.5 249.5   142
5 242.5 460.5   138
6 421.5 543.5   137
7 537.5 590.5   140
8 586.5 680.5   137

Overlap between adjacent intervals:
[1] 16 14 19 15 14 15 15
\end{Soutput}
\begin{Sinput}
> xyplot(lat ~ long | Depth, data = quakes)
\end{Sinput}
\end{Schunk}
\begin{center}
\includegraphics{figs/intro-038}
\end{center}




\newpage

\subsection*{Trivariate displays}

Of course, for continuous trivariate data, it may be more effective to
use a three-dimensional scatter plot.
\begin{Schunk}
\begin{Sinput}
> cloud(depth ~ lat * long, data = quakes,
        zlim = rev(range(quakes$depth)),
        screen = list(z = 105, x = -70), panel.aspect = 0.75,
        xlab = "Longitude", ylab = "Latitude", zlab = "Depth")
\end{Sinput}
\end{Schunk}
\begin{center}
\includegraphics{figs/intro-040}
\end{center}
Static three-dimensional scatter plots are not very useful because of
the strong effect of ``camera'' direction.  Unfortunately, \lattice\
does not allow interactive manipulation of the viewing direction.
Still, looking at a few such plots suggests that the epicenter
locations are concentrated around two planes in three-dimensional
space.


~~~Other trivariate functions are \Rfunction{wireframe} and
\Rfunction{levelplot}, which display data in the form of a
three-dimensional surface.  We will not explicitly discuss these and
the other high-level functions in \lattice, but examples can be found
in their help pages.  
\begin{exercise}
  Try changing viewing direction in the previous plot by modifying the
  \code{screen} argument.
\end{exercise}

\newpage



\subsection*{The \class{trellis} object}


One important feature of \lattice\ that makes it different from
traditional \R\ graphics is that high-level functions do not actually
plot anything.  Instead, they return an object of class
\class{trellis}, that needs to be \Rfunction{print}-ed or
\Rfunction{plot}-ed.  \R's automatic printing rule means that in most
cases, the user does not see any difference in behaviour.  Here is one
example where we use optional arguments of the \Rfunction{plot} method
for \class{trellis} objects to display two plots side by side.
\begin{Schunk}
\begin{Sinput}
> dp.uspe <-
      dotplot(t(USPersonalExpenditure), groups = FALSE, layout = c(1, 5),
              xlab = "Expenditure (billion dollars)")
> dp.uspe.log <-
      dotplot(t(USPersonalExpenditure), groups = FALSE, layout = c(1, 5),
              scales = list(x = list(log = 2)),
              xlab = "Expenditure (billion dollars)")
> plot(dp.uspe,     split = c(1, 1, 2, 1))
> plot(dp.uspe.log, split = c(2, 1, 2, 1), newpage = FALSE)
\end{Sinput}
\end{Schunk}
\includegraphics{figs/intro-041}




% \newpage


% Other topics
% \begin{itemize}
% \item panel functions
% \item scales
% \item axis - maybe
% \item objects

% \item ordering
% \item aspect ratio
% \item make.groups
% \item legends
% \end{itemize}




\newpage


\section*{Further resources}


The material we have covered should be enough that the online
documentation accompanying the \lattice\ package should begin to make
sense.  Other useful material are
\begin{itemize}
\item The Lattice book, part of Springer's \textsf{UseR!} series.  The
  book's website
  \begin{center}
    \url{http://lmdvr.r-forge.r-project.org}
  \end{center}
  contains all figures and code from  the book.
\item The Trellis website from Bell Labs
  \begin{center}
    \url{http://netlib.bell-labs.com/cm/ms/departments/sia/project/trellis/}
  \end{center}
  offers a wealth of material on Trellis that is largely applicable to
  \lattice\ as well (of course, features unique to \lattice\ are not
  covered)
\end{itemize}

\subsection*{Session information}

\begin{itemize}\raggedright
  \item R version 2.14.0 Under development (unstable) (2011-05-07 r55801), \verb|x86_64-unknown-linux-gnu|
  \item Locale: \verb|LC_CTYPE=en_IN|, \verb|LC_NUMERIC=C|, \verb|LC_TIME=en_IN|, \verb|LC_COLLATE=en_IN|, \verb|LC_MONETARY=en_IN|, \verb|LC_MESSAGES=en_IN|, \verb|LC_PAPER=C|, \verb|LC_NAME=C|, \verb|LC_ADDRESS=C|, \verb|LC_TELEPHONE=C|, \verb|LC_MEASUREMENT=en_IN|, \verb|LC_IDENTIFICATION=C|
  \item Base packages: base, datasets, graphics, grDevices,
    methods, stats, utils
  \item Other packages: lattice~0.19-26
  \item Loaded via a namespace (and not attached):
    grid~2.14.0, tools~2.14.0
\end{itemize}


\bibliography{references}
\bibliographystyle{abbrvnat}


\end{document}
